---
title: 'Visualisation of data'
author: 'Maria Singstad Paulsen'
date: '`r format(Sys.Date(), "%Y-%B-%d")`'
output:
    pdf_document:
        fig_width: 5
        fig_height: 3.5
        df_print: kable
        highlight: tango
        # default tango pygments kate monochrome espresso zenburn haddock breezedark
    fontsize: 12pt
    # highlight: atelier forest light
    # highlight: solar

    # LaTeX stuff
    # documentclass: scrartcl
    header-includes:
        - \usepackage{amsmath}
        - \usepackage{xcolor}
        - \usepackage{bm}

        # The following lines lets us use the Chancery font with its size altered
        - \DeclareFontFamily{OT1}{pzc}{}
        - \DeclareFontShape{OT1}{pzc}{m}{it}{<->s*[1.2] pzcmi7t}{}
        - \DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}
        # - \usepackage[dvipsnames]{xcolor}
---

```{r setup, include = F}
# Initial setup
knitr::opts_chunk$set(echo = TRUE)
# Fix the error "Package xcolor Warning: Incompatible color definition on input line ..."
knitr::knit_hooks$set(document = function(x) {
  sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)
})
```


```{r, echo = F, warning = F, message = F}
# Load the packages we'll use in this notebook.
library(car)
library(ggplot2)
library(reticulate)
# install.packages("NLP")
```

Load some NLP related packages / libraries
```{r}
# read in the libraries we're going to use
library(tidyverse) # general utility & workflow functions
library(tidytext) # tidy implimentation of NLP methods
library(tm) # general text mining functions, making document term matrixes
library(SnowballC) # for stemming
library(caTools) # moving window statistics, ROC, AUC
library(udpipe)
library(NLP)
```

Load the training data.
```{r, echo = F, warning = F, message = F}
train <- read.delim('/home/fero/Desktop/nlp/in5550_exam/data/raw/train.conll', header = F, quote = "", col.names = c('token', 'tag'))
summary(train); cat('\n')
str(train)
```

Load the development data.
```{r, echo = F, warning = F, message = F}
dev <- read.delim('/home/fero/Desktop/nlp/in5550_exam/data/raw/dev.conll', header = F, quote = "", col.names = c('token', 'tag'))
summary(dev); cat('\n')
str(dev)
```


Group "B-targ-Negative" with "I-targ-Negative", and "B-targ-Positive" with "I-targ-Positive". We want to inspect whether the data is skewed.
```{r}
train$polarity <- factor(train$tag, levels = levels(train$tag), labels = c('Negative', 'Positive', 'Negative', 'Positive', 'O'))
dev$polarity <- factor(dev$tag, levels = levels(dev$tag), labels = c('Negative', 'Positive', 'Negative', 'Positive', 'O'))
cat('Train\n'); summary(train$polarity); cat('\n')
cat('Dev\n'); summary(dev$polarity)
```

Group "B-targ-Negative" with "B-targ-Positive", and "I-targ-Negative" with "I-targ-Positive". We want to inspect whether the data is skewed.
```{r}
train$target <- factor(train$tag, levels = levels(train$tag), labels = c('B', 'B', 'I', 'I', 'O'))
dev$target <- factor(dev$tag, levels = levels(dev$tag), labels = c('B', 'B', 'I', 'I', 'O'))
cat('Train\n'); summary(train$target); cat('\n')
cat('Dev\n'); summary(dev$target)
```
```{r}
train_minority <- remove(train$tag, "O")

cat('Train\n'); summary(train_minority); cat('\n')

```

```{r}
barplot(table(train$polarity, train$target), horiz = T)

```

```{r}
barplot(table(dev$polarity, dev$target))
```
```{r, echo = T, warning = F, message = F, fig.align = 'center', fig.width = 8, fig.height 6, fig.cap = "Tag distribution, train" }
minority <- train$
```

```{r, echo = T, warning = F, message = F, fig.align = 'center', fig.width = 8, fig.height 6, fig.cap = "Tag distribution, train" }
ggplot(train, aes(x = tag)) +
  geom_bar() +
  ggtitle("Distribution of tags in the training dataset") +
  xlab("Tags") + 
  ylab("Frequency")
  
```

```{r}
ggplot(train, aes(x = polarity, y = target, color = tag)) +
  geom_boxplot()

```

```{r}
df = read.delim('/report/data/model_scores_partial.tsv')
summary(df); cat('\n')
str(df)

```
```{r}
df$vocab_size <- factor(df$vocab_size)
df$baseline <- factor(df$baseline, levels = c(1, 0), labels = c("True", "False"))
df$dropout <- factor(df$dropout)
df$recurrent_dropout <- factor(df$recurrent_dropout)
df$job <- factor(df$job)
df$dim <- factor(df$dim)
df$names <- factor(df$names)
df$algorithm <- factor(df$algorithm)
summary(df)
```

```{r, echo = T, warning = F, message = F, fig.align = 'center', fig.width = 8, fig.height 6, fig.cap = "Tag distribution, train" }
ggplot(df, aes(x = binary_precision, y = binary_recall)) +
  gG(aes(names)) +
  ggtitle("Binary F1 Scores") +
  xlab("Word Embeddings") + 
  ylab("Binary F1 Score")
```

```{r}
dft <- CoNLLTextDocument(train_conll, encoding = "unknown", format = c(WORD = "WORD", TAG = "TAG"), meta = list())
```

Now, click the **Run** button on the chunk toolbar to [execute](https://www.jetbrains.com/help/pycharm/r-markdown.html#run-r-code) the chunk code. The result should be placed under the chunk.
Click the **Knit and Open Document** to built and preview an output.