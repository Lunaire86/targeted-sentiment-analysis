# Targeted Sentiment Analysis
## IN5550 ‚Äí Home Exam Project
### University of Oslo ‚Äí Spring 2020

This repository accompanies the written report. In addition to my own code, it contains pre-code written by IN5550 course lecturers.

### The task in short 
*From the task description:* Fine-grained Sentiment Analysis (SA), sometimes referred to as Opinion Analysis/Mining, is the task of identifying opinions in text and analyzing them in terms of their polar expressions, targets, and holders. In this task we will focus on targeted SA, i.e. the identification of the target of opinion along with the polarity with which it is associated in the text (positive/negative). In the example below, for instance, the target of the opinion is disken ‚Äòthe disk‚Äô and it is ascribed a positive polarity by the surrounding context.

| | ùòóùòñùòö | | | |  
|:--|:--|:--|:--|:--|  
|*Denne*|**disken**|*er*|*sv√¶rt*|*stilleg√•ende*|
|This   |disk      |is  |very   |quiet-going   |  

### Data format
The dataset used is [NoReC-fine](https://github.com/ltgoslo/norec_fine), a dataset for fine-grained sentiment analysis in Norwegian. It was converted from JSON to a stripped-down version of ConLL-U for this task, and given as part of the pre-code. The labels follow the [BIO / IOB2 format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging), with added polarity, and there are a total of five labels:  

- B-targ-Positive
- I-targ-Positive
- B-targ-Negative
- I-targ-Negative
- O  

##### An example of a tagged sentence.
   
*# sent_id = 501595-13-04* 

|Token              |Tag            |
|:--                |:--            |
|Munken             |B-targ-Positive|
|Bistro             |I-targ-Positive|
|er                 |O              |
|en                 |O              |
|hyggelig           |O              |
|nabolagsrestaurant |O              |
|for                |O              |
|hverdagslige       |O              |
|og                 |O              |
|uformelle          |O              |
|anledninger        |O              |
|.                  |O              |

### Modelling
The main objective of the home exam is to train a neural system to perform targeted sentiment analysis for Norwegian text.

#### Baseline model
A simple BiLSTM-model.

#### Experimental evaluation
Evaluate the effect of at least three different changes to the basis system. The evaluation of changes to the system should be performed on the development set.

#### Held-out testing
The best configuration of your system following experimentation should be evaluated on the test set.

### Evaluation
The models will be evaluated on two different metrics: [proportional F1 and binary F1](https://en.wikipedia.org/wiki/F1_score). *Binary Overlap* counts any overlapping predicted and gold span as correct. *Proportional Overlap* instead assigns precision as the ratio of overlap with the predicted span and recall as the ratio of overlap with the gold span, which reduces to token-level F1. Proportional F1 is therefore a stricter measure than Binary F1.

### Possible directions for experimentation
1. Experimenting with alternative label encoding (e.g. BIOUL)
2. Compare *pipeline* vs. *joint prediction* approaches.
3. Impact of different architectures:
	- LSTM vs. GRU vs. Transformer
	- Include character-level information
	- Depth of model (2-layer, 3-layer, etc)
4. 
Effect of using pretrained models ([ELMo](https://github.com/HIT-SCIR/ELMoForManyLangs), [BERT](https://github.com/botxo/nordic_bert), or [Multilingual Bert](https://github.com/google-research/bert/blob/master/multilingual.md))
5. A small error analysis (confusion matrix, the most common errors).  

------------
Project Organisation 
------------


    ‚îú‚îÄ‚îÄ LICENSE              <- Not added yet. Reason: exam 
    ‚îú‚îÄ‚îÄ README.md            <- The top-level README for developers using this project.
    ‚îÇ
    ‚îú‚îÄ‚îÄ babil                <- Source code for use in this project.
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py      <- Makes babil a Python module. Babil approves of this.
    ‚îÇ   ‚îú‚îÄ‚îÄ __main__.py      <- Makes babil callable. Hello!
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ coleus           <- Word embeddings model trainer.
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py    <- Argument parsing and configurations for coleus.
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ helpers.py   <- Helper methods for coleus.
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model.py     <- The class containing the model. 
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ data             <- Scripts to download or generate data.
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ features         <- Scripts to turn raw data into features for modeling.
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îú‚îÄ‚îÄ models           <- Scripts to train models and then use trained models 
    ‚îÇ   ‚îÇ   ‚îÇ                   to make predictions.
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baseline.py  < 
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fasttext.py
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ improved.py
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ run.py
    ‚îÇ   ‚îÇ
    ‚îÇ   ‚îî‚îÄ‚îÄ  utils            <- Scripts containing helper functions 
    ‚îÇ       ‚îî‚îÄ‚îÄ config.py     <- Argument parsing and configurations for babil.
    ‚îÇ       ‚îú‚îÄ‚îÄ helpers.py    <- Helper methods for coleus.
    ‚îÇ       ‚îî‚îÄ‚îÄ metrics.py    <- Model metrics class.
    ‚îú‚îÄ‚îÄ data
    ‚îÇ   ‚îú‚îÄ‚îÄ interim          <- Intermediate data that has been transformed.
    ‚îÇ   ‚îú‚îÄ‚îÄ processed        <- The final, canonical data sets for modeling.                
    ‚îÇ   ‚îî‚îÄ‚îÄ raw              <- The original, immutable data dump.
    ‚îÇ
    ‚îú‚îÄ‚îÄ embeddings           <- Smaller embeddings for running tests locally.
    ‚îÇ
    ‚îú‚îÄ‚îÄ figures              <- Anything related to data visualisation.
    ‚îÇ
    ‚îú‚îÄ‚îÄ logs                 <- Log files.
    ‚îÇ
    ‚îú‚îÄ‚îÄ misc                 <- If it fits, it sits... Or something along those lines.
    ‚îÇ
    ‚îú‚îÄ‚îÄ models               <- Trained and serialized models, model predictions, or model summaries
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebooks            <- Jupyter notebooks.
    ‚îÇ
    ‚îú‚îÄ‚îÄ references           <- Data dictionaries, manuals, and all other explanatory materials.
    ‚îÇ
    ‚îú‚îÄ‚îÄ reports              <- Generated analysis as HTML, PDF, LaTeX, etc.
    ‚îÇ   ‚îî‚îÄ‚îÄ figures          <- Generated graphics and figures to be used in reporting.
    ‚îÇ
    ‚îú‚îÄ‚îÄ environment.yml      <- The environment file for reproducing the analysis enviroment using Conda.             
    ‚îÇ
    ‚îú‚îÄ‚îÄ requirements.txt     <- The requirements file for reproducing the analysis environment, e.g.
    ‚îÇ                           generated with `pip freeze > requirements.txt`.
    ‚îÇ
    ‚îú‚îÄ‚îÄ path_config.json     <- Keeps track of the various paths used to load or save projects.
    ‚îÇ
    ‚îú‚îÄ‚îÄ conllu_parser.sh     <- Script for parsing CoNNL-U files, in batch, to one sentence per line.
    ‚îÇ
    ‚îú‚îÄ‚îÄ setup.py             <- makes project pip installable (pip install -e .) so src can be imported.
    ‚îÇ        
    ‚îî‚îÄ‚îÄ SEED.txt             <- Much seed. Very strong. Wow.

--------
